#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
YOLOæ¨¡å‹è®­ç»ƒè„šæœ¬
æ­¤è„šæœ¬ç”¨äºè®­ç»ƒYOLOæ¨¡å‹ï¼Œæ”¯æŒå¤šç§é…ç½®å’Œè‡ªåŠ¨åŒ–è®­ç»ƒæµç¨‹
"""

import sys
import os
from pathlib import Path
import argparse
import logging
import yaml
from datetime import datetime
import torch
import torch.cuda

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
FILE = Path(__file__).resolve()
ROOT = FILE.parents[0]
if str(ROOT) not in sys.path:
    sys.path.append(str(ROOT))

from ultralytics import YOLO
from ultralytics.utils import LOGGER
from ultralytics.utils.torch_utils import select_device

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def check_environment():
    """
    æ£€æŸ¥è®­ç»ƒç¯å¢ƒ
    """
    logger.info("=" * 60)
    logger.info("ğŸ” ç¯å¢ƒæ£€æŸ¥")
    logger.info("=" * 60)
    
    # Pythonç‰ˆæœ¬
    python_version = sys.version.split()[0]
    logger.info(f"ğŸ Pythonç‰ˆæœ¬: {python_version}")
    
    # PyTorchç‰ˆæœ¬
    logger.info(f"ğŸ”¥ PyTorchç‰ˆæœ¬: {torch.__version__}")
    
    # CUDAæ£€æŸ¥
    if torch.cuda.is_available():
        cuda_version = torch.version.cuda
        gpu_count = torch.cuda.device_count()
        current_gpu = torch.cuda.current_device()
        gpu_name = torch.cuda.get_device_name(current_gpu)
        gpu_memory = torch.cuda.get_device_properties(current_gpu).total_memory / 1024**3
        
        logger.info(f"âœ… CUDAå¯ç”¨: {cuda_version}")
        logger.info(f"ğŸ® GPUæ•°é‡: {gpu_count}")
        logger.info(f"ğŸ¯ å½“å‰GPU: {gpu_name}")
        logger.info(f"ğŸ’¾ GPUå†…å­˜: {gpu_memory:.1f}GB")
    else:
        logger.warning("âš ï¸  CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰")
    
    logger.info("=" * 60)

def create_data_yaml(data_dir, yaml_path, class_names=None):
    """
    åˆ›å»ºæ•°æ®é…ç½®YAMLæ–‡ä»¶
    
    Args:
        data_dir (str): æ•°æ®é›†ç›®å½•è·¯å¾„
        yaml_path (str): YAMLæ–‡ä»¶ä¿å­˜è·¯å¾„
        class_names (list): ç±»åˆ«åç§°åˆ—è¡¨
    """
    data_dir = Path(data_dir)
    
    # é»˜è®¤ç±»åˆ«åç§°
    if class_names is None:
        class_names = ['person', 'vehicle', 'animal']  # æ ¹æ®ä½ çš„éœ€æ±‚ä¿®æ”¹
    
    # åˆ›å»ºYAMLé…ç½®
    yaml_config = {
        'path': str(data_dir.absolute()),
        'train': 'train/images',
        'val': 'val/images',
        'test': 'test/images',
        'nc': len(class_names),
        'names': class_names
    }
    
    # ä¿å­˜YAMLæ–‡ä»¶
    with open(yaml_path, 'w', encoding='utf-8') as f:
        yaml.dump(yaml_config, f, default_flow_style=False, allow_unicode=True)
    
    logger.info(f"ğŸ“ å·²åˆ›å»ºæ•°æ®é…ç½®æ–‡ä»¶: {yaml_path}")
    return yaml_path

def validate_dataset(data_yaml):
    """
    éªŒè¯æ•°æ®é›†ç»“æ„
    
    Args:
        data_yaml (str): æ•°æ®é›†é…ç½®æ–‡ä»¶è·¯å¾„
    """
    logger.info("ğŸ” éªŒè¯æ•°æ®é›†ç»“æ„...")
    
    try:
        with open(data_yaml, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        data_path = Path(config['path'])
        train_images = data_path / config['train']
        val_images = data_path / config['val']
        train_labels = train_images.parent / 'labels'
        val_labels = val_images.parent / 'labels'
        
        # æ£€æŸ¥ç›®å½•ç»“æ„
        required_dirs = [train_images, val_images, train_labels, val_labels]
        for dir_path in required_dirs:
            if not dir_path.exists():
                logger.warning(f"âš ï¸  ç›®å½•ä¸å­˜åœ¨: {dir_path}")
            else:
                file_count = len(list(dir_path.glob("*.*")))
                logger.info(f"âœ… {dir_path.name}: {file_count} ä¸ªæ–‡ä»¶")
        
        logger.info(f"ğŸ“Š æ•°æ®é›†ç±»åˆ«æ•°: {config['nc']}")
        logger.info(f"ğŸ·ï¸  ç±»åˆ«åç§°: {config['names']}")
        
    except Exception as e:
        logger.error(f"âŒ æ•°æ®é›†éªŒè¯å¤±è´¥: {str(e)}")
        return False
    
    return True

def train_model(
    model_name="yolo11n.pt",
    data_yaml="data.yaml",
    epochs=100,
    batch_size=16,
    image_size=640,
    device="",
    project="runs/train",
    name="exp",
    resume=False,
    save_period=10,
    patience=10,
    workers=8,
    lr0=0.01,
    warmup_epochs=3,
    mosaic=1.0,
    mixup=0.0,
    copy_paste=0.0,
    degrees=0.0,
    translate=0.1,
    scale=0.5,
    shear=0.0,
    perspective=0.0,
    flipud=0.0,
    fliplr=0.5,
    hsv_h=0.015,
    hsv_s=0.7,
    hsv_v=0.4
):
    """
    è®­ç»ƒYOLOæ¨¡å‹
    
    Args:
        model_name (str): é¢„è®­ç»ƒæ¨¡å‹åç§°æˆ–è·¯å¾„
        data_yaml (str): æ•°æ®é›†é…ç½®æ–‡ä»¶è·¯å¾„
        epochs (int): è®­ç»ƒè½®æ•°
        batch_size (int): æ‰¹æ¬¡å¤§å°
        image_size (int): å›¾åƒå¤§å°
        device (str): è®¾å¤‡é€‰æ‹©
        project (str): é¡¹ç›®ä¿å­˜ç›®å½•
        name (str): å®éªŒåç§°
        resume (bool): æ˜¯å¦æ¢å¤è®­ç»ƒ
        save_period (int): ä¿å­˜é—´éš”
        patience (int): æ—©åœè€å¿ƒå€¼
        workers (int): æ•°æ®åŠ è½½å™¨å·¥ä½œè¿›ç¨‹æ•°
        lr0 (float): åˆå§‹å­¦ä¹ ç‡
        warmup_epochs (int): é¢„çƒ­è½®æ•°
        å…¶ä»–å‚æ•°ç”¨äºæ•°æ®å¢å¼ºé…ç½®
    """
    try:
        # ç¯å¢ƒæ£€æŸ¥
        check_environment()
        
        # éªŒè¯æ•°æ®é›†
        if not os.path.exists(data_yaml):
            logger.error(f"âŒ æ•°æ®é›†é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {data_yaml}")
            return None
        
        if not validate_dataset(data_yaml):
            logger.error("âŒ æ•°æ®é›†éªŒè¯å¤±è´¥")
            return None
        
        # åŠ è½½æ¨¡å‹
        logger.info(f"ğŸš€ å¼€å§‹è®­ç»ƒæ¨¡å‹: {model_name}")
        logger.info(f"ğŸ“Š æ•°æ®é›†é…ç½®: {data_yaml}")
        
        model = YOLO(model_name)
        
        # è®¾å¤‡é€‰æ‹©
        if not device:
            device = select_device()
        logger.info(f"ğŸ¯ ä½¿ç”¨è®¾å¤‡: {device}")
        
        # è®­ç»ƒé…ç½®
        train_config = {
            'data': data_yaml,
            'epochs': epochs,
            'batch': batch_size,
            'imgsz': image_size,
            'device': device,
            'project': project,
            'name': name,
            'resume': resume,
            'save_period': save_period,
            'patience': patience,
            'workers': workers,
            'lr0': lr0,
            'warmup_epochs': warmup_epochs,
            'mosaic': mosaic,
            'mixup': mixup,
            'copy_paste': copy_paste,
            'degrees': degrees,
            'translate': translate,
            'scale': scale,
            'shear': shear,
            'perspective': perspective,
            'flipud': flipud,
            'fliplr': fliplr,
            'hsv_h': hsv_h,
            'hsv_s': hsv_s,
            'hsv_v': hsv_v,
            'verbose': True,
            'save': True,
            'cache': False,  # æ ¹æ®å†…å­˜æƒ…å†µè°ƒæ•´
            'rect': False,   # çŸ©å½¢è®­ç»ƒ
            'cos_lr': False, # ä½™å¼¦å­¦ä¹ ç‡è°ƒåº¦
            'close_mosaic': 10,  # æœ€åå‡ è½®å…³é—­é©¬èµ›å…‹
            'amp': True,     # è‡ªåŠ¨æ··åˆç²¾åº¦
        }
        
        logger.info("=" * 60)
        logger.info("ğŸ“‹ è®­ç»ƒé…ç½®:")
        for key, value in train_config.items():
            if key not in ['data']:  # è·³è¿‡é•¿è·¯å¾„
                logger.info(f"  {key}: {value}")
        logger.info("=" * 60)
        
        # å¼€å§‹è®­ç»ƒ
        start_time = datetime.now()
        logger.info(f"ğŸ¬ è®­ç»ƒå¼€å§‹æ—¶é—´: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
        
        results = model.train(**train_config)
        
        end_time = datetime.now()
        training_duration = end_time - start_time
        
        logger.info("=" * 60)
        logger.info("ğŸ‰ è®­ç»ƒå®Œæˆ!")
        logger.info(f"â±ï¸  è®­ç»ƒæ—¶é•¿: {training_duration}")
        logger.info(f"ğŸ“ æ¨¡å‹ä¿å­˜åœ¨: {model.trainer.save_dir}")
        logger.info("=" * 60)
        
        # æ˜¾ç¤ºè®­ç»ƒç»“æœ
        if hasattr(results, 'results_dict'):
            logger.info("ğŸ“Š æœ€ç»ˆè®­ç»ƒæŒ‡æ ‡:")
            for key, value in results.results_dict.items():
                if isinstance(value, (int, float)):
                    logger.info(f"  {key}: {value:.4f}")
        
        return str(model.trainer.save_dir)
        
    except Exception as e:
        logger.error(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        return None

def validate_model(model_path, data_yaml, device=""):
    """
    éªŒè¯è®­ç»ƒåçš„æ¨¡å‹
    
    Args:
        model_path (str): æ¨¡å‹è·¯å¾„
        data_yaml (str): æ•°æ®é›†é…ç½®æ–‡ä»¶
        device (str): è®¾å¤‡é€‰æ‹©
    """
    try:
        logger.info("ğŸ” å¼€å§‹æ¨¡å‹éªŒè¯...")
        
        model = YOLO(model_path)
        
        # è¿è¡ŒéªŒè¯
        metrics = model.val(
            data=data_yaml,
            device=device,
            verbose=True
        )
        
        logger.info("=" * 60)
        logger.info("ğŸ“Š éªŒè¯ç»“æœ:")
        logger.info(f"  mAP50: {metrics.box.map50:.4f}")
        logger.info(f"  mAP50-95: {metrics.box.map:.4f}")
        logger.info(f"  Precision: {metrics.box.mp:.4f}")
        logger.info(f"  Recall: {metrics.box.mr:.4f}")
        logger.info("=" * 60)
        
        return metrics
        
    except Exception as e:
        logger.error(f"âŒ æ¨¡å‹éªŒè¯å¤±è´¥: {str(e)}")
        return None

def main():
    """å‘½ä»¤è¡Œå…¥å£å‡½æ•°"""
    parser = argparse.ArgumentParser(description="YOLOæ¨¡å‹è®­ç»ƒè„šæœ¬")
    
    # åŸºæœ¬å‚æ•°
    parser.add_argument("--model", type=str, default="yolo11n.pt", help="é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„")
    parser.add_argument("--data", type=str, default="data.yaml", help="æ•°æ®é›†é…ç½®æ–‡ä»¶")
    parser.add_argument("--epochs", type=int, default=100, help="è®­ç»ƒè½®æ•°")
    parser.add_argument("--batch", type=int, default=16, help="æ‰¹æ¬¡å¤§å°")
    parser.add_argument("--imgsz", type=int, default=640, help="å›¾åƒå¤§å°")
    parser.add_argument("--device", type=str, default="", help="è®¾å¤‡é€‰æ‹© (cpu, 0, 1, ...)")
    
    # è®­ç»ƒè®¾ç½®
    parser.add_argument("--project", type=str, default="runs/train", help="é¡¹ç›®ä¿å­˜ç›®å½•")
    parser.add_argument("--name", type=str, default="exp", help="å®éªŒåç§°")
    parser.add_argument("--resume", action="store_true", help="æ¢å¤è®­ç»ƒ")
    parser.add_argument("--save-period", type=int, default=10, help="ä¿å­˜é—´éš”")
    parser.add_argument("--patience", type=int, default=10, help="æ—©åœè€å¿ƒå€¼")
    
    # ä¼˜åŒ–å™¨å‚æ•°
    parser.add_argument("--lr0", type=float, default=0.01, help="åˆå§‹å­¦ä¹ ç‡")
    parser.add_argument("--warmup-epochs", type=int, default=3, help="é¢„çƒ­è½®æ•°")
    
    # æ•°æ®å¢å¼ºå‚æ•°
    parser.add_argument("--mosaic", type=float, default=1.0, help="é©¬èµ›å…‹å¢å¼ºæ¦‚ç‡")
    parser.add_argument("--mixup", type=float, default=0.0, help="MixUpå¢å¼ºæ¦‚ç‡")
    parser.add_argument("--degrees", type=float, default=0.0, help="æ—‹è½¬è§’åº¦")
    parser.add_argument("--translate", type=float, default=0.1, help="å¹³ç§»æ¯”ä¾‹")
    parser.add_argument("--scale", type=float, default=0.5, help="ç¼©æ”¾æ¯”ä¾‹")
    parser.add_argument("--fliplr", type=float, default=0.5, help="æ°´å¹³ç¿»è½¬æ¦‚ç‡")
    
    # å…¶ä»–å‚æ•°
    parser.add_argument("--validate", action="store_true", help="è®­ç»ƒåéªŒè¯æ¨¡å‹")
    parser.add_argument("--create-data", type=str, help="åˆ›å»ºæ•°æ®é…ç½®æ–‡ä»¶çš„æ•°æ®é›†ç›®å½•")
    parser.add_argument("--class-names", nargs='+', help="ç±»åˆ«åç§°åˆ—è¡¨")
    
    args = parser.parse_args()
    
    # åˆ›å»ºæ•°æ®é…ç½®æ–‡ä»¶
    if args.create_data:
        create_data_yaml(args.create_data, args.data, args.class_names)
        logger.info(f"âœ… æ•°æ®é…ç½®æ–‡ä»¶å·²åˆ›å»º: {args.data}")
        return
    
    # å¼€å§‹è®­ç»ƒ
    save_dir = train_model(
        model_name=args.model,
        data_yaml=args.data,
        epochs=args.epochs,
        batch_size=args.batch,
        image_size=args.imgsz,
        device=args.device,
        project=args.project,
        name=args.name,
        resume=args.resume,
        save_period=args.save_period,
        patience=args.patience,
        lr0=args.lr0,
        warmup_epochs=args.warmup_epochs,
        mosaic=args.mosaic,
        mixup=args.mixup,
        degrees=args.degrees,
        translate=args.translate,
        scale=args.scale,
        fliplr=args.fliplr
    )
    
    if save_dir and args.validate:
        best_model = os.path.join(save_dir, "weights", "best.pt")
        if os.path.exists(best_model):
            validate_model(best_model, args.data, args.device)

if __name__ == "__main__":
    # ç›´æ¥è¿è¡Œçš„é»˜è®¤é…ç½®
    # ä½ å¯ä»¥åœ¨è¿™é‡Œä¿®æ”¹é»˜è®¤çš„è®­ç»ƒå‚æ•°
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®é…ç½®
    data_yaml = "custom_data.yaml"
    
    # å¦‚æœæ•°æ®é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ›å»ºä¸€ä¸ªç¤ºä¾‹
    if not os.path.exists(data_yaml):
        logger.info("ğŸ“ åˆ›å»ºç¤ºä¾‹æ•°æ®é…ç½®æ–‡ä»¶...")
        sample_config = {
            'path': './datasets/custom',
            'train': 'train/images',
            'val': 'val/images',
            'test': 'test/images',
            'nc': 80,  # ç±»åˆ«æ•°é‡
            'names': ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',
                     'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',
                     'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',
                     'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',
                     'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',
                     'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',
                     'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard',
                     'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase',
                     'scissors', 'teddy bear', 'hair drier', 'toothbrush']
        }
        
        with open(data_yaml, 'w', encoding='utf-8') as f:
            yaml.dump(sample_config, f, default_flow_style=False, allow_unicode=True)
        
        logger.info(f"âœ… å·²åˆ›å»ºç¤ºä¾‹æ•°æ®é…ç½®æ–‡ä»¶: {data_yaml}")
        logger.info("âš ï¸  è¯·æ ¹æ®ä½ çš„æ•°æ®é›†ä¿®æ”¹é…ç½®æ–‡ä»¶")
    
    # é»˜è®¤è®­ç»ƒå‚æ•°
    train_model(
        model_name="yolo11n.pt",     # ä½¿ç”¨YOLOv11 nanoæ¨¡å‹
        data_yaml=data_yaml,          # æ•°æ®é…ç½®æ–‡ä»¶
        epochs=100,                   # è®­ç»ƒè½®æ•°
        batch_size=16,                # æ‰¹æ¬¡å¤§å°
        image_size=640,               # å›¾åƒå¤§å°
        device="",                    # è‡ªåŠ¨é€‰æ‹©è®¾å¤‡
        project="runs/train",         # ä¿å­˜ç›®å½•
        name="custom_model",          # å®éªŒåç§°
        lr0=0.01,                     # åˆå§‹å­¦ä¹ ç‡
        patience=20                   # æ—©åœè€å¿ƒå€¼
    )
